{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ddfa63d",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e45a5858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e98bb25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "052d3795",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8153efcf",
   "metadata": {},
   "source": [
    "## Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7399d279",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'NUM_WORKERS':4,\n",
    "    'ANTIGEN_WINDOW':128,\n",
    "    'ANTIGEN_MAX_LEN':128, # ANTIGEN_WINDOW와 ANTIGEN_MAX_LEN은 같아야합니다.\n",
    "    'EPITOPE_MAX_LEN':256,\n",
    "    'EPOCHS':20,\n",
    "    'LEARNING_RATE':1e-3,\n",
    "    'BATCH_SIZE':2048,\n",
    "    'THRESHOLD':0.5,\n",
    "    'SEED':41\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebdf7e0",
   "metadata": {},
   "source": [
    "## Fixed RandomSeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1b8941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1562f9",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "34737d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessing(data_type, new_df):\n",
    "    alpha_map = {\n",
    "                'A':0, 'B':1, 'C':2, 'D':3, 'E':4, 'F':5,\n",
    "                'G':6, 'H':7, 'I':8, 'J':9, 'K':10, 'L':11,\n",
    "                'M':12, 'N':13, 'O':14, 'P':15, 'Q':16, 'R':17,\n",
    "                'S':18, 'T':19, 'U':20, 'V':21, 'W':22, 'X':23,\n",
    "                'Y':24, 'Z':25, '<PAD>':26,\n",
    "            }\n",
    "\n",
    "    epitope_list = []\n",
    "    left_antigen_list = []\n",
    "    right_antigen_list = []\n",
    "    \n",
    "    for epitope, antigen, s_p, e_p in tqdm(zip(new_df['epitope_seq'], new_df['antigen_seq'], new_df['start_position'], new_df['end_position'])):\n",
    "        epitope_pad = [26 for _ in range(CFG['EPITOPE_MAX_LEN'])] # 길이 맞춰주기 위한 패딩. 모두 같은 feature를 가져야 함\n",
    "        left_antigen_pad = [26 for _ in range(CFG['ANTIGEN_MAX_LEN'])]\n",
    "        right_antigen_pad = [26 for _ in range(CFG['ANTIGEN_MAX_LEN'])]\n",
    "        \n",
    "        epitope = [alpha_map[x] for x in epitope]\n",
    "        \n",
    "        # Left antigen : [start_position-WINDOW : start_position]\n",
    "        # Right antigen : [end_position : end_position+WINDOW]\n",
    "\n",
    "        start_position = s_p-CFG['ANTIGEN_WINDOW']-1\n",
    "        end_position = e_p+CFG['ANTIGEN_WINDOW']\n",
    "        if start_position < 0:\n",
    "            start_position = 0\n",
    "        if end_position > len(antigen):\n",
    "            end_position = len(antigen)\n",
    "        \n",
    "        # left / right antigen sequence 추출\n",
    "        left_antigen = antigen[int(start_position) : int(s_p)-1]\n",
    "        left_antigen = [alpha_map[x] for x in left_antigen]\n",
    "        \n",
    "        right_antigen = antigen[int(e_p) : int(end_position)]\n",
    "        right_antigen = [alpha_map[x] for x in right_antigen]\n",
    "\n",
    "        if CFG['EPITOPE_MAX_LEN']<len(epitope):\n",
    "            epitope_pad[:len(epitope)] = epitope[:CFG['EPITOPE_MAX_LEN']]\n",
    "        else:\n",
    "            epitope_pad[:len(epitope)] = epitope[:]\n",
    "\n",
    "        left_antigen_pad[:len(left_antigen)] = left_antigen[:]\n",
    "        right_antigen_pad[:len(right_antigen)] = right_antigen[:]\n",
    "        \n",
    "        epitope_list.append(epitope_pad)\n",
    "        left_antigen_list.append(left_antigen_pad)\n",
    "        right_antigen_list.append(right_antigen_pad)\n",
    "    \n",
    "    label_list = None\n",
    "    if data_type != 'test':\n",
    "        label_list = []\n",
    "        for label in new_df['label']:\n",
    "            label_list.append(label)\n",
    "    print(f'{data_type} dataframe preprocessing was done.')\n",
    "    return epitope_list, left_antigen_list, right_antigen_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4b0118db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>epitope_seq</th>\n",
       "      <th>antigen_seq</th>\n",
       "      <th>antigen_code</th>\n",
       "      <th>start_position</th>\n",
       "      <th>end_position</th>\n",
       "      <th>number_of_tested</th>\n",
       "      <th>number_of_responses</th>\n",
       "      <th>assay_method_technique</th>\n",
       "      <th>assay_group</th>\n",
       "      <th>disease_type</th>\n",
       "      <th>disease_state</th>\n",
       "      <th>reference_date</th>\n",
       "      <th>reference_journal</th>\n",
       "      <th>reference_title</th>\n",
       "      <th>reference_IRI</th>\n",
       "      <th>qualitative_label</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200001</td>\n",
       "      <td>KGILSN</td>\n",
       "      <td>AFKGILSNADIKAAEAACFKEGSFDEDGFYAKVGLDAFSADELKKL...</td>\n",
       "      <td>P02622.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>antigen inhibition</td>\n",
       "      <td>qualitative binding</td>\n",
       "      <td>Occurrence of allergy</td>\n",
       "      <td>allergic disease</td>\n",
       "      <td>1976</td>\n",
       "      <td>Int Arch Allergy Appl Immunol</td>\n",
       "      <td>The allergenic structure of allergen M from co...</td>\n",
       "      <td>http://www.iedb.org/reference/1005599</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200002</td>\n",
       "      <td>SNADIK</td>\n",
       "      <td>AFKGILSNADIKAAEAACFKEGSFDEDGFYAKVGLDAFSADELKKL...</td>\n",
       "      <td>P02622.1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>antigen inhibition</td>\n",
       "      <td>qualitative binding</td>\n",
       "      <td>Occurrence of allergy</td>\n",
       "      <td>allergic disease</td>\n",
       "      <td>1976</td>\n",
       "      <td>Int Arch Allergy Appl Immunol</td>\n",
       "      <td>The allergenic structure of allergen M from co...</td>\n",
       "      <td>http://www.iedb.org/reference/1005599</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200003</td>\n",
       "      <td>EGSFDEDGFYAKVGLDAFSADELK</td>\n",
       "      <td>AFKGILSNADIKAAEAACFKEGSFDEDGFYAKVGLDAFSADELKKL...</td>\n",
       "      <td>P02622.1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>antigen inhibition</td>\n",
       "      <td>qualitative binding</td>\n",
       "      <td>Occurrence of allergy</td>\n",
       "      <td>allergic disease</td>\n",
       "      <td>1976</td>\n",
       "      <td>Int Arch Allergy Appl Immunol</td>\n",
       "      <td>The allergenic structure of allergen M from co...</td>\n",
       "      <td>http://www.iedb.org/reference/1005599</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200004</td>\n",
       "      <td>SFDEDGFY</td>\n",
       "      <td>AFKGILSNADIKAAEAACFKEGSFDEDGFYAKVGLDAFSADELKKL...</td>\n",
       "      <td>P02622.1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>antigen inhibition</td>\n",
       "      <td>qualitative binding</td>\n",
       "      <td>Occurrence of allergy</td>\n",
       "      <td>allergic disease</td>\n",
       "      <td>1976</td>\n",
       "      <td>Int Arch Allergy Appl Immunol</td>\n",
       "      <td>The allergenic structure of allergen M from co...</td>\n",
       "      <td>http://www.iedb.org/reference/1005599</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200005</td>\n",
       "      <td>DEDGFY</td>\n",
       "      <td>AFKGILSNADIKAAEAACFKEGSFDEDGFYAKVGLDAFSADELKKL...</td>\n",
       "      <td>P02622.1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>antigen inhibition</td>\n",
       "      <td>qualitative binding</td>\n",
       "      <td>Occurrence of allergy</td>\n",
       "      <td>allergic disease</td>\n",
       "      <td>1976</td>\n",
       "      <td>Int Arch Allergy Appl Immunol</td>\n",
       "      <td>The allergenic structure of allergen M from co...</td>\n",
       "      <td>http://www.iedb.org/reference/1005599</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190806</th>\n",
       "      <td>390807</td>\n",
       "      <td>QQFKRELRNLPQQCGLRAPQRCDLEVESGGRDRY</td>\n",
       "      <td>MAKLTILVALALFLLAAHASARQQWELQGDRRCQSQLERANLRPCE...</td>\n",
       "      <td>Q6PSU2.2</td>\n",
       "      <td>139.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ELISA</td>\n",
       "      <td>qualitative binding</td>\n",
       "      <td>Occurrence of allergy</td>\n",
       "      <td>peanut allergy</td>\n",
       "      <td>2022</td>\n",
       "      <td>J Allergy Clin Immunol</td>\n",
       "      <td>Immunodominant conformational and linear IgE e...</td>\n",
       "      <td>http://www.iedb.org/reference/1040321</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190807</th>\n",
       "      <td>390808</td>\n",
       "      <td>RCMCEALQQIMENQSDRLQGRQQE</td>\n",
       "      <td>MAKLTILVALALFLLAAHASARQQWELQGDRRCQSQLERANLRPCE...</td>\n",
       "      <td>Q6PSU2.2</td>\n",
       "      <td>115.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>antigen inhibition</td>\n",
       "      <td>qualitative binding</td>\n",
       "      <td>Occurrence of allergy</td>\n",
       "      <td>peanut allergy</td>\n",
       "      <td>2022</td>\n",
       "      <td>J Allergy Clin Immunol</td>\n",
       "      <td>Immunodominant conformational and linear IgE e...</td>\n",
       "      <td>http://www.iedb.org/reference/1040321</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190808</th>\n",
       "      <td>390809</td>\n",
       "      <td>QRDEDSYGRDPYSPSQDPYSPSPYDRRGAGSSQHQERCCNELNEFENNQ</td>\n",
       "      <td>MAKLTILVALALFLLAAHASARQQWELQGDRRCQSQLERANLRPCE...</td>\n",
       "      <td>QHN95793.1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>antigen inhibition</td>\n",
       "      <td>qualitative binding</td>\n",
       "      <td>Occurrence of allergy</td>\n",
       "      <td>peanut allergy</td>\n",
       "      <td>2022</td>\n",
       "      <td>J Allergy Clin Immunol</td>\n",
       "      <td>Immunodominant conformational and linear IgE e...</td>\n",
       "      <td>http://www.iedb.org/reference/1040321</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190809</th>\n",
       "      <td>390810</td>\n",
       "      <td>RQQWELQGDRRCQSQLERANLRPCEQHLMQKI</td>\n",
       "      <td>MAKLTILVALALFLLAAHASARQQWELQGDRRCQSQLERANLRPCE...</td>\n",
       "      <td>Q6PSU2.2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>antigen inhibition</td>\n",
       "      <td>qualitative binding</td>\n",
       "      <td>Occurrence of allergy</td>\n",
       "      <td>peanut allergy</td>\n",
       "      <td>2022</td>\n",
       "      <td>J Allergy Clin Immunol</td>\n",
       "      <td>Immunodominant conformational and linear IgE e...</td>\n",
       "      <td>http://www.iedb.org/reference/1040321</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190810</th>\n",
       "      <td>390811</td>\n",
       "      <td>YMLDLQPET</td>\n",
       "      <td>MHGDTPTLHEYMLDLQPETTDLYCYEQLNDSSEEEDEIDGPAGQAE...</td>\n",
       "      <td>P03129.1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>binding assay</td>\n",
       "      <td>qualitative binding</td>\n",
       "      <td>No immunization</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022</td>\n",
       "      <td>PLoS One</td>\n",
       "      <td>A TCR mimic monoclonal antibody for the HPV-16...</td>\n",
       "      <td>http://www.iedb.org/reference/1040344</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190811 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                        epitope_seq  \\\n",
       "0       200001                                             KGILSN   \n",
       "1       200002                                             SNADIK   \n",
       "2       200003                           EGSFDEDGFYAKVGLDAFSADELK   \n",
       "3       200004                                           SFDEDGFY   \n",
       "4       200005                                             DEDGFY   \n",
       "...        ...                                                ...   \n",
       "190806  390807                 QQFKRELRNLPQQCGLRAPQRCDLEVESGGRDRY   \n",
       "190807  390808                           RCMCEALQQIMENQSDRLQGRQQE   \n",
       "190808  390809  QRDEDSYGRDPYSPSQDPYSPSPYDRRGAGSSQHQERCCNELNEFENNQ   \n",
       "190809  390810                   RQQWELQGDRRCQSQLERANLRPCEQHLMQKI   \n",
       "190810  390811                                          YMLDLQPET   \n",
       "\n",
       "                                              antigen_seq antigen_code  \\\n",
       "0       AFKGILSNADIKAAEAACFKEGSFDEDGFYAKVGLDAFSADELKKL...     P02622.1   \n",
       "1       AFKGILSNADIKAAEAACFKEGSFDEDGFYAKVGLDAFSADELKKL...     P02622.1   \n",
       "2       AFKGILSNADIKAAEAACFKEGSFDEDGFYAKVGLDAFSADELKKL...     P02622.1   \n",
       "3       AFKGILSNADIKAAEAACFKEGSFDEDGFYAKVGLDAFSADELKKL...     P02622.1   \n",
       "4       AFKGILSNADIKAAEAACFKEGSFDEDGFYAKVGLDAFSADELKKL...     P02622.1   \n",
       "...                                                   ...          ...   \n",
       "190806  MAKLTILVALALFLLAAHASARQQWELQGDRRCQSQLERANLRPCE...     Q6PSU2.2   \n",
       "190807  MAKLTILVALALFLLAAHASARQQWELQGDRRCQSQLERANLRPCE...     Q6PSU2.2   \n",
       "190808  MAKLTILVALALFLLAAHASARQQWELQGDRRCQSQLERANLRPCE...   QHN95793.1   \n",
       "190809  MAKLTILVALALFLLAAHASARQQWELQGDRRCQSQLERANLRPCE...     Q6PSU2.2   \n",
       "190810  MHGDTPTLHEYMLDLQPETTDLYCYEQLNDSSEEEDEIDGPAGQAE...     P03129.1   \n",
       "\n",
       "        start_position  end_position  number_of_tested  number_of_responses  \\\n",
       "0                  3.0           8.0               NaN                  NaN   \n",
       "1                  7.0          12.0               NaN                  NaN   \n",
       "2                 21.0          44.0               NaN                  NaN   \n",
       "3                 23.0          30.0               NaN                  NaN   \n",
       "4                 25.0          30.0               NaN                  NaN   \n",
       "...                ...           ...               ...                  ...   \n",
       "190806           139.0         172.0              21.0                  0.0   \n",
       "190807           115.0         138.0               NaN                  NaN   \n",
       "190808            54.0         102.0               NaN                  NaN   \n",
       "190809            22.0          53.0               NaN                  NaN   \n",
       "190810            11.0          19.0               NaN                  NaN   \n",
       "\n",
       "       assay_method_technique          assay_group           disease_type  \\\n",
       "0          antigen inhibition  qualitative binding  Occurrence of allergy   \n",
       "1          antigen inhibition  qualitative binding  Occurrence of allergy   \n",
       "2          antigen inhibition  qualitative binding  Occurrence of allergy   \n",
       "3          antigen inhibition  qualitative binding  Occurrence of allergy   \n",
       "4          antigen inhibition  qualitative binding  Occurrence of allergy   \n",
       "...                       ...                  ...                    ...   \n",
       "190806                  ELISA  qualitative binding  Occurrence of allergy   \n",
       "190807     antigen inhibition  qualitative binding  Occurrence of allergy   \n",
       "190808     antigen inhibition  qualitative binding  Occurrence of allergy   \n",
       "190809     antigen inhibition  qualitative binding  Occurrence of allergy   \n",
       "190810          binding assay  qualitative binding        No immunization   \n",
       "\n",
       "           disease_state  reference_date              reference_journal  \\\n",
       "0       allergic disease            1976  Int Arch Allergy Appl Immunol   \n",
       "1       allergic disease            1976  Int Arch Allergy Appl Immunol   \n",
       "2       allergic disease            1976  Int Arch Allergy Appl Immunol   \n",
       "3       allergic disease            1976  Int Arch Allergy Appl Immunol   \n",
       "4       allergic disease            1976  Int Arch Allergy Appl Immunol   \n",
       "...                  ...             ...                            ...   \n",
       "190806    peanut allergy            2022         J Allergy Clin Immunol   \n",
       "190807    peanut allergy            2022         J Allergy Clin Immunol   \n",
       "190808    peanut allergy            2022         J Allergy Clin Immunol   \n",
       "190809    peanut allergy            2022         J Allergy Clin Immunol   \n",
       "190810               NaN            2022                       PLoS One   \n",
       "\n",
       "                                          reference_title  \\\n",
       "0       The allergenic structure of allergen M from co...   \n",
       "1       The allergenic structure of allergen M from co...   \n",
       "2       The allergenic structure of allergen M from co...   \n",
       "3       The allergenic structure of allergen M from co...   \n",
       "4       The allergenic structure of allergen M from co...   \n",
       "...                                                   ...   \n",
       "190806  Immunodominant conformational and linear IgE e...   \n",
       "190807  Immunodominant conformational and linear IgE e...   \n",
       "190808  Immunodominant conformational and linear IgE e...   \n",
       "190809  Immunodominant conformational and linear IgE e...   \n",
       "190810  A TCR mimic monoclonal antibody for the HPV-16...   \n",
       "\n",
       "                                reference_IRI qualitative_label  label  \n",
       "0       http://www.iedb.org/reference/1005599          Positive      1  \n",
       "1       http://www.iedb.org/reference/1005599          Positive      1  \n",
       "2       http://www.iedb.org/reference/1005599          Positive      1  \n",
       "3       http://www.iedb.org/reference/1005599          Positive      1  \n",
       "4       http://www.iedb.org/reference/1005599          Positive      1  \n",
       "...                                       ...               ...    ...  \n",
       "190806  http://www.iedb.org/reference/1040321          Negative      0  \n",
       "190807  http://www.iedb.org/reference/1040321          Positive      1  \n",
       "190808  http://www.iedb.org/reference/1040321          Positive      1  \n",
       "190809  http://www.iedb.org/reference/1040321          Positive      1  \n",
       "190810  http://www.iedb.org/reference/1040344          Positive      1  \n",
       "\n",
       "[190811 rows x 18 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df = pd.read_csv('./data/open/train.csv')\n",
    "# Split Train : Validation = 0.8 : 0.2\n",
    "train_len = int(len(all_df)*0.8)\n",
    "train_df = all_df.iloc[:train_len]\n",
    "val_df = all_df.iloc[train_len:]\n",
    "\n",
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5f626991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "152648it [00:05, 29204.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataframe preprocessing was done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38163it [00:02, 17658.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val dataframe preprocessing was done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_epitope_list, train_left_antigen_list, train_right_antigen_list, train_label_list = get_preprocessing('train', train_df)\n",
    "val_epitope_list, val_left_antigen_list, val_right_antigen_list, val_label_list = get_preprocessing('val', val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28753e69",
   "metadata": {},
   "source": [
    "## CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2e2ff935",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, epitope_list, left_antigen_list, right_antigen_list, label_list):\n",
    "        self.epitope_list = epitope_list\n",
    "        self.left_antigen_list = left_antigen_list\n",
    "        self.right_antigen_list = right_antigen_list\n",
    "        self.label_list = label_list\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        self.epitope = self.epitope_list[index]\n",
    "        self.left_antigen = self.left_antigen_list[index]\n",
    "        self.right_antigen = self.right_antigen_list[index]\n",
    "        \n",
    "        if self.label_list is not None:\n",
    "            self.label = self.label_list[index]\n",
    "            return torch.tensor(self.epitope), torch.tensor(self.left_antigen), torch.tensor(self.right_antigen), self.label\n",
    "        else:\n",
    "            return torch.tensor(self.epitope), torch.tensor(self.left_antigen), torch.tensor(self.right_antigen)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.epitope_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fc25a38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_epitope_list, train_left_antigen_list, train_right_antigen_list, train_label_list)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True)\n",
    "\n",
    "val_dataset = CustomDataset(val_epitope_list, val_left_antigen_list, val_right_antigen_list, val_label_list)\n",
    "val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "578a87f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_node = 15\n",
    "hidden_dim = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd4a897",
   "metadata": {},
   "source": [
    "## Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2ead4f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 epitope_length=CFG['EPITOPE_MAX_LEN'],\n",
    "                 epitope_emb_node=emb_node,\n",
    "                 epitope_hidden_dim=hidden_dim,\n",
    "                 left_antigen_length=CFG['ANTIGEN_MAX_LEN'],\n",
    "                 left_antigen_emb_node=emb_node,\n",
    "                 left_antigen_hidden_dim=hidden_dim,\n",
    "                 right_antigen_length=CFG['ANTIGEN_MAX_LEN'],\n",
    "                 right_antigen_emb_node=emb_node,\n",
    "                 right_antigen_hidden_dim=hidden_dim,\n",
    "                 lstm_bidirect=True\n",
    "                ):\n",
    "        super(BaseModel, self).__init__()\n",
    "        # Embedding Layer\n",
    "        self.epitope_embed = nn.Embedding(num_embeddings=27, # 0 ~ 26 까지 숫자로 맵핑했으므로\n",
    "                                          embedding_dim=epitope_emb_node, \n",
    "                                          padding_idx=26\n",
    "                                         )\n",
    "        self.left_antigen_embed = nn.Embedding(num_embeddings=27,\n",
    "                                          embedding_dim=left_antigen_emb_node, \n",
    "                                          padding_idx=26\n",
    "                                         )\n",
    "        self.right_antigen_embed = nn.Embedding(num_embeddings=27,\n",
    "                                          embedding_dim=right_antigen_emb_node, \n",
    "                                          padding_idx=26\n",
    "                                         )\n",
    "        # LSTM\n",
    "        self.epitope_lstm = nn.LSTM(input_size=epitope_emb_node, \n",
    "                                    hidden_size=epitope_hidden_dim, \n",
    "                                    batch_first=True, \n",
    "                                    bidirectional=lstm_bidirect\n",
    "                                   )\n",
    "        self.left_antigen_lstm = nn.LSTM(input_size=left_antigen_emb_node, \n",
    "                                    hidden_size=left_antigen_hidden_dim, \n",
    "                                    batch_first=True, \n",
    "                                    bidirectional=lstm_bidirect\n",
    "                                   )\n",
    "        self.right_antigen_lstm = nn.LSTM(input_size=right_antigen_emb_node, \n",
    "                                    hidden_size=right_antigen_hidden_dim, \n",
    "                                    batch_first=True, \n",
    "                                    bidirectional=lstm_bidirect\n",
    "                                   )\n",
    "\n",
    "        # Classifier\n",
    "        if lstm_bidirect:\n",
    "            in_channels = 2*(epitope_hidden_dim+left_antigen_hidden_dim+right_antigen_hidden_dim)\n",
    "        else:\n",
    "            in_channels = epitope_hidden_dim+left_antigen_hidden_dim+right_antigen_hidden_dim\n",
    "        \n",
    "        # dropout = torch.nn.Dropout(p=0.2)\n",
    "        # self.classifier = nn.Sequential(\n",
    "        #     nn.LeakyReLU(True),\n",
    "        #     nn.BatchNorm1d(in_channels),\n",
    "        #     dropout,\n",
    "        #     nn.Linear(in_channels, in_channels//4),\n",
    "        #     nn.LeakyReLU(True),\n",
    "        #     nn.BatchNorm1d(in_channels//4),\n",
    "        #     dropout,\n",
    "        #     nn.Linear(in_channels//4, 1)\n",
    "        # )\n",
    "        \n",
    "    def forward(self, epitope_x, left_antigen_x, right_antigen_x):\n",
    "        BATCH_SIZE = epitope_x.size(0)\n",
    "        # Get Embedding Vector\n",
    "        epitope_x = self.epitope_embed(epitope_x)\n",
    "        left_antigen_x = self.left_antigen_embed(left_antigen_x)\n",
    "        right_antigen_x = self.right_antigen_embed(right_antigen_x)\n",
    "        \n",
    "        # LSTM\n",
    "        epitope_hidden, _ = self.epitope_lstm(epitope_x)\n",
    "        epitope_hidden = epitope_hidden[:,-1,:] # output dimension은 (batch, time_step, hidden dimension) 순이다. 양방향일 경우 hidden_size*2\n",
    "\n",
    "        left_antigen_hidden, _ = self.left_antigen_lstm(left_antigen_x)\n",
    "        left_antigen_hidden = left_antigen_hidden[:,-1,:]\n",
    "        \n",
    "        right_antigen_hidden, _ = self.right_antigen_lstm(right_antigen_x)\n",
    "        right_antigen_hidden = right_antigen_hidden[:,-1,:]\n",
    "        \n",
    "        # Feature Concat -> Binary Classifier\n",
    "        x = torch.cat([epitope_hidden, left_antigen_hidden, right_antigen_hidden], axis=-1)\n",
    "        # x = self.classifier(x).view(-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "edabc013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(output, is_train):\n",
    "    in_channels = 2 * (hidden_dim * 3)\n",
    "    dropout = torch.nn.Dropout(p=0.2)\n",
    "    train_classifier = nn.Sequential(\n",
    "        nn.LeakyReLU(True),\n",
    "        nn.BatchNorm1d(in_channels),\n",
    "        dropout,\n",
    "        nn.Linear(in_channels, in_channels//4),\n",
    "        nn.LeakyReLU(True),\n",
    "        nn.BatchNorm1d(in_channels//4),\n",
    "        dropout,\n",
    "        nn.Linear(in_channels//4, 1)\n",
    "    )\n",
    "\n",
    "    val_classifier = nn.Sequential(\n",
    "        nn.LeakyReLU(True),\n",
    "        nn.BatchNorm1d(in_channels),\n",
    "        nn.Linear(in_channels, in_channels//4),\n",
    "        nn.LeakyReLU(True),\n",
    "        nn.BatchNorm1d(in_channels//4),\n",
    "        nn.Linear(in_channels//4, 1)\n",
    "    )\n",
    "\n",
    "    if (is_train):\n",
    "        output = train_classifier(output).view(-1)\n",
    "    else :\n",
    "        output = val_classifier(output).view(-1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb1d5b9",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "804e329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    model.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss().to(device) \n",
    "    \n",
    "    best_val_f1 = 0\n",
    "    for epoch in range(1, CFG['EPOCHS']+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for epitope_seq, left_antigen_seq, right_antigen_seq, label in tqdm(iter(train_loader)):\n",
    "            epitope_seq = epitope_seq.to(device)\n",
    "            left_antigen_seq = left_antigen_seq.to(device)\n",
    "            right_antigen_seq = right_antigen_seq.to(device)\n",
    "            label = label.float().to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(epitope_seq, left_antigen_seq, right_antigen_seq)\n",
    "            output = classifier(output, is_train=True)\n",
    "            loss = criterion(output, label)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "            \n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "                    \n",
    "        val_loss, val_f1 = validation(model, val_loader, criterion, device)\n",
    "        print(f'Epoch : [{epoch}] Train Loss : [{np.mean(train_loss):.5f}] Val Loss : [{val_loss:.5f}] Val F1 : [{val_f1:.5f}]')\n",
    "        \n",
    "        if best_val_f1 < val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            torch.save(model.state_dict(), './best_model.pth', _use_new_zipfile_serialization=False)\n",
    "            print('Model Saved.')\n",
    "    return best_val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "daab2ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    pred_proba_label = []\n",
    "    true_label = []\n",
    "    val_loss = []\n",
    "    with torch.no_grad():\n",
    "        for epitope_seq, left_antigen_seq, right_antigen_seq, label in tqdm(iter(val_loader)):\n",
    "            epitope_seq = epitope_seq.to(device)\n",
    "            left_antigen_seq = left_antigen_seq.to(device)\n",
    "            right_antigen_seq = right_antigen_seq.to(device)\n",
    "            label = label.float().to(device)\n",
    "            \n",
    "            model_pred = model(epitope_seq, left_antigen_seq, right_antigen_seq)\n",
    "            model_pred = classifier(model_pred, is_train=False)\n",
    "            loss = criterion(model_pred, label)\n",
    "            model_pred = torch.sigmoid(model_pred).to('cpu')\n",
    "            \n",
    "            pred_proba_label += model_pred.tolist()\n",
    "            true_label += label.to('cpu').tolist()\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "            \n",
    "    pred_label = np.where(np.array(pred_proba_label)>CFG['THRESHOLD'], 1, 0)\n",
    "    val_f1 = f1_score(true_label, pred_label, average='macro')\n",
    "    return np.mean(val_loss), val_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697f70f5",
   "metadata": {},
   "source": [
    "## Run!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bf2bc1b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [12:48<00:00, 10.25s/it]\n",
      "100%|██████████| 19/19 [01:46<00:00,  5.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1] Train Loss : [0.74082] Val Loss : [0.72378] Val F1 : [0.44084]\n",
      "Model Saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 21/75 [04:16<10:58, 12.19s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/haeunko/Documents/codes/pytorch_exercise/kaggle/epitope/baseline_code.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/haeunko/Documents/codes/pytorch_exercise/kaggle/epitope/baseline_code.ipynb#ch0000021?line=2'>3</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(params \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mparameters(), lr \u001b[39m=\u001b[39m CFG[\u001b[39m\"\u001b[39m\u001b[39mLEARNING_RATE\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/haeunko/Documents/codes/pytorch_exercise/kaggle/epitope/baseline_code.ipynb#ch0000021?line=3'>4</a>\u001b[0m scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mCosineAnnealingLR(optimizer, T_max\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(train_loader)\u001b[39m*\u001b[39mCFG[\u001b[39m'\u001b[39m\u001b[39mEPOCHS\u001b[39m\u001b[39m'\u001b[39m], eta_min\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/haeunko/Documents/codes/pytorch_exercise/kaggle/epitope/baseline_code.ipynb#ch0000021?line=5'>6</a>\u001b[0m best_score \u001b[39m=\u001b[39m train(model, optimizer, train_loader, val_loader, scheduler, device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/haeunko/Documents/codes/pytorch_exercise/kaggle/epitope/baseline_code.ipynb#ch0000021?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mBest Validation F1 Score : [\u001b[39m\u001b[39m{\u001b[39;00mbest_score\u001b[39m:\u001b[39;00m\u001b[39m.5f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/Users/haeunko/Documents/codes/pytorch_exercise/kaggle/epitope/baseline_code.ipynb Cell 24\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, train_loader, val_loader, scheduler, device)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/haeunko/Documents/codes/pytorch_exercise/kaggle/epitope/baseline_code.ipynb#ch0000021?line=12'>13</a>\u001b[0m label \u001b[39m=\u001b[39m label\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/haeunko/Documents/codes/pytorch_exercise/kaggle/epitope/baseline_code.ipynb#ch0000021?line=14'>15</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/haeunko/Documents/codes/pytorch_exercise/kaggle/epitope/baseline_code.ipynb#ch0000021?line=16'>17</a>\u001b[0m output \u001b[39m=\u001b[39m model(epitope_seq, left_antigen_seq, right_antigen_seq)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/haeunko/Documents/codes/pytorch_exercise/kaggle/epitope/baseline_code.ipynb#ch0000021?line=17'>18</a>\u001b[0m output \u001b[39m=\u001b[39m classifier(output, is_train\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/haeunko/Documents/codes/pytorch_exercise/kaggle/epitope/baseline_code.ipynb#ch0000021?line=18'>19</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, label)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/kaggle/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1052\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/haeunko/Documents/codes/pytorch_exercise/kaggle/epitope/baseline_code.ipynb Cell 24\u001b[0m in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, epitope_x, left_antigen_x, right_antigen_x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/haeunko/Documents/codes/pytorch_exercise/kaggle/epitope/baseline_code.ipynb#ch0000021?line=67'>68</a>\u001b[0m right_antigen_x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright_antigen_embed(right_antigen_x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/haeunko/Documents/codes/pytorch_exercise/kaggle/epitope/baseline_code.ipynb#ch0000021?line=69'>70</a>\u001b[0m \u001b[39m# LSTM\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/haeunko/Documents/codes/pytorch_exercise/kaggle/epitope/baseline_code.ipynb#ch0000021?line=70'>71</a>\u001b[0m epitope_hidden, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepitope_lstm(epitope_x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/haeunko/Documents/codes/pytorch_exercise/kaggle/epitope/baseline_code.ipynb#ch0000021?line=71'>72</a>\u001b[0m epitope_hidden \u001b[39m=\u001b[39m epitope_hidden[:,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,:] \u001b[39m# output dimension은 (batch, time_step, hidden dimension) 순이다. 양방향일 경우 hidden_size*2\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/haeunko/Documents/codes/pytorch_exercise/kaggle/epitope/baseline_code.ipynb#ch0000021?line=73'>74</a>\u001b[0m left_antigen_hidden, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft_antigen_lstm(left_antigen_x)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/kaggle/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1052\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/kaggle/lib/python3.8/site-packages/torch/nn/modules/rnn.py:679\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 679\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[1;32m    680\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[1;32m    681\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    682\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[1;32m    683\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = BaseModel()\n",
    "model.eval()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_loader)*CFG['EPOCHS'], eta_min=0)\n",
    "\n",
    "best_score = train(model, optimizer, train_loader, val_loader, scheduler, device)\n",
    "print(f'Best Validation F1 Score : [{best_score:.5f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e70e8be-b74c-4776-b58a-87daabb459f6",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "358984ba-ea99-480b-847f-1144e171b9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "120944it [00:04, 26991.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test dataframe preprocessing was done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('./data/open/test.csv')\n",
    "test_epitope_list, test_left_antigen_list, test_right_antigen_list, test_label_list = get_preprocessing('test', test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c4ed31ff-b110-49fc-96bd-7f3fddcbcaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(test_epitope_list, test_left_antigen_list, test_right_antigen_list, None)\n",
    "test_loader = DataLoader(test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "440a7b3b-e508-4e82-a5a1-42c50ac468d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModel(\n",
       "  (epitope_embed): Embedding(27, 15, padding_idx=26)\n",
       "  (left_antigen_embed): Embedding(27, 15, padding_idx=26)\n",
       "  (right_antigen_embed): Embedding(27, 15, padding_idx=26)\n",
       "  (epitope_lstm): LSTM(15, 64, batch_first=True, bidirectional=True)\n",
       "  (left_antigen_lstm): LSTM(15, 64, batch_first=True, bidirectional=True)\n",
       "  (right_antigen_lstm): LSTM(15, 64, batch_first=True, bidirectional=True)\n",
       "  (classifier): Sequential(\n",
       "    (0): LeakyReLU(negative_slope=True)\n",
       "    (1): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Linear(in_features=384, out_features=96, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=True)\n",
       "    (4): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): Linear(in_features=96, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BaseModel()\n",
    "best_checkpoint = torch.load('./best_model.pth')\n",
    "model.load_state_dict(best_checkpoint)\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c7e25a7a-3c9b-42d3-8762-6e76389f61b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    model.eval()\n",
    "    pred_proba_label = []\n",
    "    with torch.no_grad():\n",
    "        for epitope_seq, left_antigen_seq, right_antigen_seq in tqdm(iter(test_loader)):\n",
    "            epitope_seq = epitope_seq.to(device)\n",
    "            left_antigen_seq = left_antigen_seq.to(device)\n",
    "            right_antigen_seq = right_antigen_seq.to(device)\n",
    "            \n",
    "            model_pred = model(epitope_seq, left_antigen_seq, right_antigen_seq)\n",
    "            model_pred = torch.sigmoid(model_pred).to('cpu')\n",
    "            \n",
    "            pred_proba_label += model_pred.tolist()\n",
    "    \n",
    "    pred_label = np.where(np.array(pred_proba_label)>CFG['THRESHOLD'], 1, 0)\n",
    "    return pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8f6a3f55-b50b-4ff5-ae3d-000fdee50ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [05:15<00:00,  5.26s/it]\n"
     ]
    }
   ],
   "source": [
    "preds = inference(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1ba0ba-6089-4403-9e56-eb14e022b016",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3c74547c-a57d-4ac2-9036-cdbf5ac952aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./data/open/sample_submission.csv')\n",
    "submit['label'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4aa20c89-f3d4-44c2-a2b0-dbd9fb506288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "submit.to_csv('./result/submit.csv', index=False)\n",
    "print('Done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('kaggle')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8ff90b7467efba29adad4c428f30fc97df3bd261ce7bef875145cebf7b584f4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
