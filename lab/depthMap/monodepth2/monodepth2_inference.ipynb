{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"monodepth2_inference.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNqD11JkTIl70/OYuJoK7Yf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4a7e7R40BiO2","executionInfo":{"status":"ok","timestamp":1661475592456,"user_tz":-540,"elapsed":1054,"user":{"displayName":"Haeun Ko","userId":"00138316170718484361"}},"outputId":"ea5d2252-ef39-4b58-8d00-954afefc40e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'monodepth2'...\n","remote: Enumerating objects: 180, done.\u001b[K\n","remote: Total 180 (delta 0), reused 0 (delta 0), pack-reused 180\u001b[K\n","Receiving objects: 100% (180/180), 10.27 MiB | 22.76 MiB/s, done.\n","Resolving deltas: 100% (89/89), done.\n"]}],"source":["!git clone https://github.com/nianticlabs/monodepth2.git"]},{"cell_type":"code","source":["!pip install tensorboardX==1.4"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2SjQUH4nEZrw","executionInfo":{"status":"ok","timestamp":1661475629723,"user_tz":-540,"elapsed":5155,"user":{"displayName":"Haeun Ko","userId":"00138316170718484361"}},"outputId":"28e64e58-93d3-4616-d84d-88b3eb4f19a8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorboardX==1.4\n","  Downloading tensorboardX-1.4-py2.py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 2.9 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX==1.4) (1.21.6)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX==1.4) (1.15.0)\n","Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX==1.4) (3.17.3)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-1.4\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HQvf3C9iEjNo","executionInfo":{"status":"ok","timestamp":1661475664560,"user_tz":-540,"elapsed":18972,"user":{"displayName":"Haeun Ko","userId":"00138316170718484361"}},"outputId":"3bf131a8-fb8a-4ee9-b357-c66f547159f8"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["img_dir = '/content/drive/MyDrive/Colab_Notebooks/pytorch/code/lab/data/test_data_jpg/'\n","img = img_dir + '003.jpg'"],"metadata":{"id":"xj8i_6djG1Ww","executionInfo":{"status":"ok","timestamp":1661475667369,"user_tz":-540,"elapsed":343,"user":{"displayName":"Haeun Ko","userId":"00138316170718484361"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["cd /content/monodepth2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9FmDU0nzI_0L","executionInfo":{"status":"ok","timestamp":1661475706784,"user_tz":-540,"elapsed":336,"user":{"displayName":"Haeun Ko","userId":"00138316170718484361"}},"outputId":"090349a2-0881-4b62-a33e-5f852bf7b9c8"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/monodepth2\n"]}]},{"cell_type":"code","source":["!python test_simple.py --image_path '/content/drive/MyDrive/Colab_Notebooks/pytorch/code/lab/data/test_data_jpg/003.jpg' --model_name mono+stereo_640x192"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tgw42QnuHSaY","executionInfo":{"status":"ok","timestamp":1661475732522,"user_tz":-540,"elapsed":14481,"user":{"displayName":"Haeun Ko","userId":"00138316170718484361"}},"outputId":"dfe72b50-2e77-451d-ded8-186c9c5e7a1d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["-> Downloading pretrained model to models/mono+stereo_640x192.zip\n","   Unzipping model...\n","   Model unzipped to models/mono+stereo_640x192\n","-> Loading model from  models/mono+stereo_640x192\n","   Loading pretrained encoder\n","/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:136: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and will be removed in 0.15. Please use keyword parameter(s) instead.\n","  f\"Using {sequence_to_str(tuple(keyword_only_kwargs.keys()), separate_last='and ')} as positional \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n","   Loading pretrained decoder\n","-> Predicting on 1 test images\n","   Processed 1 of 1 images - saved predictions to:\n","   - /content/drive/MyDrive/Colab_Notebooks/pytorch/code/lab/data/test_data_jpg/003_disp.jpeg\n","   - /content/drive/MyDrive/Colab_Notebooks/pytorch/code/lab/data/test_data_jpg/003_disp.npy\n","-> Done!\n"]}]},{"cell_type":"code","source":["!python test_simple.py --image_path '/content/drive/MyDrive/Colab_Notebooks/pytorch/code/lab/data/test_data_jpg/003.jpg' --model_name mono+stereo_640x192 --pred_metric_depth"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pXicoKWEJ03d","executionInfo":{"status":"ok","timestamp":1661047660720,"user_tz":-540,"elapsed":4928,"user":{"displayName":"Haeun Ko","userId":"00138316170718484361"}},"outputId":"3f4e4dad-9d76-4bef-f07c-0a6a77e365aa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["-> Loading model from  models/mono+stereo_640x192\n","   Loading pretrained encoder\n","/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:136: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and will be removed in 0.15. Please use keyword parameter(s) instead.\n","  f\"Using {sequence_to_str(tuple(keyword_only_kwargs.keys()), separate_last='and ')} as positional \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n","   Loading pretrained decoder\n","-> Predicting on 1 test images\n","   Processed 1 of 1 images - saved predictions to:\n","   - /content/drive/MyDrive/Colab_Notebooks/pytorch/code/lab/data/test_data_jpg/003_disp.jpeg\n","   - /content/drive/MyDrive/Colab_Notebooks/pytorch/code/lab/data/test_data_jpg/003_depth.npy\n","-> Done!\n"]}]},{"cell_type":"markdown","source":["### Inference code"],"metadata":{"id":"N-6PuN-UgM6Y"}},{"cell_type":"code","source":["# Copyright Niantic 2019. Patent Pending. All rights reserved.\n","#\n","# This software is licensed under the terms of the Monodepth2 licence\n","# which allows for non-commercial use only, the full terms of which are made\n","# available in the LICENSE file.\n","\n","from __future__ import absolute_import, division, print_function\n","\n","import os\n","import sys\n","import glob\n","import argparse\n","import numpy as np\n","import PIL.Image as pil\n","import matplotlib as mpl\n","import matplotlib.cm as cm\n","\n","import torch\n","from torchvision import transforms, datasets\n","\n","import networks\n","from layers import disp_to_depth\n","from utils import download_model_if_doesnt_exist\n","from evaluate_depth import STEREO_SCALE_FACTOR\n","\n","\n","def parse_args():\n","    parser = argparse.ArgumentParser(\n","        description='Simple testing funtion for Monodepthv2 models.')\n","\n","    parser.add_argument('--image_path', type=str,\n","                        help='path to a test image or folder of images', required=True)\n","    parser.add_argument('--model_name', type=str,\n","                        help='name of a pretrained model to use',\n","                        choices=[\n","                            \"mono_640x192\",\n","                            \"stereo_640x192\",\n","                            \"mono+stereo_640x192\",\n","                            \"mono_no_pt_640x192\",\n","                            \"stereo_no_pt_640x192\",\n","                            \"mono+stereo_no_pt_640x192\",\n","                            \"mono_1024x320\",\n","                            \"stereo_1024x320\",\n","                            \"mono+stereo_1024x320\"])\n","    parser.add_argument('--ext', type=str,\n","                        help='image extension to search for in folder', default=\"jpg\")\n","    parser.add_argument(\"--no_cuda\",\n","                        help='if set, disables CUDA',\n","                        action='store_true')\n","    parser.add_argument(\"--pred_metric_depth\",\n","                        help='if set, predicts metric depth instead of disparity. (This only '\n","                             'makes sense for stereo-trained KITTI models).',\n","                        action='store_true')\n","\n","    return parser.parse_args()\n","\n","\n","def test_simple(args):\n","    \"\"\"Function to predict for a single image or folder of images\n","    \"\"\"\n","    assert args.model_name is not None, \\\n","        \"You must specify the --model_name parameter; see README.md for an example\"\n","\n","    if torch.cuda.is_available() and not args.no_cuda:\n","        device = torch.device(\"cuda\")\n","    else:\n","        device = torch.device(\"cpu\")\n","\n","    if args.pred_metric_depth and \"stereo\" not in args.model_name:\n","        print(\"Warning: The --pred_metric_depth flag only makes sense for stereo-trained KITTI \"\n","              \"models. For mono-trained models, output depths will not in metric space.\")\n","\n","    download_model_if_doesnt_exist(args.model_name)\n","    model_path = os.path.join(\"models\", args.model_name)\n","    print(\"-> Loading model from \", model_path)\n","    encoder_path = os.path.join(model_path, \"encoder.pth\")\n","    depth_decoder_path = os.path.join(model_path, \"depth.pth\")\n","\n","    # LOADING PRETRAINED MODEL\n","    print(\"   Loading pretrained encoder\")\n","    encoder = networks.ResnetEncoder(18, False)\n","    loaded_dict_enc = torch.load(encoder_path, map_location=device)\n","\n","    # extract the height and width of image that this model was trained with\n","    feed_height = loaded_dict_enc['height']\n","    feed_width = loaded_dict_enc['width']\n","    filtered_dict_enc = {k: v for k, v in loaded_dict_enc.items() if k in encoder.state_dict()}\n","    encoder.load_state_dict(filtered_dict_enc)\n","    encoder.to(device)\n","    encoder.eval()\n","\n","    print(\"   Loading pretrained decoder\")\n","    depth_decoder = networks.DepthDecoder(\n","        num_ch_enc=encoder.num_ch_enc, scales=range(4))\n","\n","    loaded_dict = torch.load(depth_decoder_path, map_location=device)\n","    depth_decoder.load_state_dict(loaded_dict)\n","\n","    depth_decoder.to(device)\n","    depth_decoder.eval()\n","\n","    # FINDING INPUT IMAGES\n","    if os.path.isfile(args.image_path):\n","        # Only testing on a single image\n","        paths = [args.image_path]\n","        output_directory = os.path.dirname(args.image_path)\n","    elif os.path.isdir(args.image_path):\n","        # Searching folder for images\n","        paths = glob.glob(os.path.join(args.image_path, '*.{}'.format(args.ext)))\n","        output_directory = args.image_path\n","    else:\n","        raise Exception(\"Can not find args.image_path: {}\".format(args.image_path))\n","\n","    print(\"-> Predicting on {:d} test images\".format(len(paths)))\n","\n","    # PREDICTING ON EACH IMAGE IN TURN\n","    with torch.no_grad():\n","        for idx, image_path in enumerate(paths):\n","\n","            if image_path.endswith(\"_disp.jpg\"):\n","                # don't try to predict disparity for a disparity image!\n","                continue\n","\n","            # Load image and preprocess\n","            input_image = pil.open(image_path).convert('RGB')\n","            original_width, original_height = input_image.size\n","            input_image = input_image.resize((feed_width, feed_height), pil.LANCZOS)\n","            input_image = transforms.ToTensor()(input_image).unsqueeze(0)\n","\n","            # PREDICTION\n","            input_image = input_image.to(device)\n","            features = encoder(input_image)\n","            outputs = depth_decoder(features)\n","\n","            disp = outputs[(\"disp\", 0)]\n","            disp_resized = torch.nn.functional.interpolate(\n","                disp, (original_height, original_width), mode=\"bilinear\", align_corners=False)\n","\n","            # Saving numpy file\n","            output_name = os.path.splitext(os.path.basename(image_path))[0]\n","            scaled_disp, depth = disp_to_depth(disp, 0.1, 100)\n","            if args.pred_metric_depth:\n","                name_dest_npy = os.path.join(output_directory, \"{}_depth.npy\".format(output_name))\n","                metric_depth = STEREO_SCALE_FACTOR * depth.cpu().numpy()\n","                np.save(name_dest_npy, metric_depth)\n","            else:\n","                name_dest_npy = os.path.join(output_directory, \"{}_disp.npy\".format(output_name))\n","                np.save(name_dest_npy, scaled_disp.cpu().numpy())\n","\n","            # Saving colormapped depth image\n","            disp_resized_np = disp_resized.squeeze().cpu().numpy()\n","            vmax = np.percentile(disp_resized_np, 95)\n","            normalizer = mpl.colors.Normalize(vmin=disp_resized_np.min(), vmax=vmax)\n","            mapper = cm.ScalarMappable(norm=normalizer, cmap='magma')\n","            colormapped_im = (mapper.to_rgba(disp_resized_np)[:, :, :3] * 255).astype(np.uint8)\n","            im = pil.fromarray(colormapped_im)\n","\n","            name_dest_im = os.path.join(output_directory, \"{}_disp.jpeg\".format(output_name))\n","            im.save(name_dest_im)\n","\n","            print(\"   Processed {:d} of {:d} images - saved predictions to:\".format(\n","                idx + 1, len(paths)))\n","            print(\"   - {}\".format(name_dest_im))\n","            print(\"   - {}\".format(name_dest_npy))\n","\n","    print('-> Done!')\n","\n","\n","if __name__ == '__main__':\n","    args = parse_args()\n","    test_simple(args)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":242},"id":"hWAzr89mgMUY","executionInfo":{"status":"error","timestamp":1661389064512,"user_tz":-540,"elapsed":4689,"user":{"displayName":"Haeun Ko","userId":"00138316170718484361"}},"outputId":"938a8f2c-d7b2-4dfd-d520-60aed7c98408"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["usage: ipykernel_launcher.py [-h] --image_path IMAGE_PATH\n","                             [--model_name {mono_640x192,stereo_640x192,mono+stereo_640x192,mono_no_pt_640x192,stereo_no_pt_640x192,mono+stereo_no_pt_640x192,mono_1024x320,stereo_1024x320,mono+stereo_1024x320}]\n","                             [--ext EXT] [--no_cuda] [--pred_metric_depth]\n","ipykernel_launcher.py: error: the following arguments are required: --image_path\n"]},{"output_type":"error","ename":"SystemExit","evalue":"ignored","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n","  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"]}]}]}