{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"mask_DINO.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP5jHOhUGjj7QoqE7sahJGZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RXGf0wRW1zrf","executionInfo":{"status":"ok","timestamp":1660008155022,"user_tz":-540,"elapsed":2956,"user":{"displayName":"Haeun Ko","userId":"00138316170718484361"}},"outputId":"2d2b10b4-e217-48c5-e3b7-ee478c09331d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'DINO'...\n","remote: Enumerating objects: 321, done.\u001b[K\n","remote: Counting objects: 100% (66/66), done.\u001b[K\n","remote: Compressing objects: 100% (37/37), done.\u001b[K\n","remote: Total 321 (delta 39), reused 32 (delta 29), pack-reused 255\u001b[K\n","Receiving objects: 100% (321/321), 13.41 MiB | 6.65 MiB/s, done.\n","Resolving deltas: 100% (107/107), done.\n"]}],"source":["!git clone https://github.com/IDEACVR/DINO"]},{"cell_type":"code","source":["!pip3 install torch==1.9.0 torchvision==0.10.0 torchaudio==0.9.0 --extra-index-url https://download.pytorch.org/whl/lts/1.9/cu102\n","!pip install MultiScaleDeformableAttention"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wrYcWEtcLT9r","executionInfo":{"status":"ok","timestamp":1660008281708,"user_tz":-540,"elapsed":123470,"user":{"displayName":"Haeun Ko","userId":"00138316170718484361"}},"outputId":"1b4c5129-7a5a-4f25-a29b-ad4ad3565883"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/lts/1.9/cu102\n","Collecting torch==1.9.0\n","  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n","\u001b[K     |████████████████████████████████| 831.4 MB 2.8 kB/s \n","\u001b[?25hCollecting torchvision==0.10.0\n","  Downloading torchvision-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (22.1 MB)\n","\u001b[K     |████████████████████████████████| 22.1 MB 1.4 MB/s \n","\u001b[?25hCollecting torchaudio==0.9.0\n","  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 46.7 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0) (4.1.1)\n","Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0) (1.21.6)\n","Installing collected packages: torch, torchvision, torchaudio\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.0+cu113\n","    Uninstalling torch-1.12.0+cu113:\n","      Successfully uninstalled torch-1.12.0+cu113\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.13.0+cu113\n","    Uninstalling torchvision-0.13.0+cu113:\n","      Successfully uninstalled torchvision-0.13.0+cu113\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 0.12.0+cu113\n","    Uninstalling torchaudio-0.12.0+cu113:\n","      Successfully uninstalled torchaudio-0.12.0+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.13.0 requires torch==1.12.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.9.0 torchaudio-0.9.0 torchvision-0.10.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","\u001b[31mERROR: Could not find a version that satisfies the requirement MultiScaleDeformableAttention (from versions: none)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for MultiScaleDeformableAttention\u001b[0m\n"]}]},{"cell_type":"code","source":["import torch\n","print(torch.__version__)\n","torch.cuda.is_available()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rl-F7ideLY3e","executionInfo":{"status":"ok","timestamp":1660008095044,"user_tz":-540,"elapsed":582,"user":{"displayName":"Haeun Ko","userId":"00138316170718484361"}},"outputId":"01b214bb-188d-463b-db8a-be6551121778"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["1.9.0+cu102\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":["cd DINO"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Kvlnvcl2XfE","executionInfo":{"status":"ok","timestamp":1660007484229,"user_tz":-540,"elapsed":284,"user":{"displayName":"Haeun Ko","userId":"00138316170718484361"}},"outputId":"1f838789-8320-4731-c5d2-ab116dd9ac1e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/DINO\n"]}]},{"cell_type":"code","source":["!pip install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"StGDuhIw3SKO","executionInfo":{"status":"ok","timestamp":1660007497784,"user_tz":-540,"elapsed":12360,"user":{"displayName":"Haeun Ko","userId":"00138316170718484361"}},"outputId":"9012d9d8-0654-49ae-b915-e5405fbdfa89"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pycocotools\n","  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-install-wo2iehu9/pycocotools_1d107799f83e46afbad13c0fa02db5cb\n","  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-install-wo2iehu9/pycocotools_1d107799f83e46afbad13c0fa02db5cb\n","Collecting panopticapi\n","  Cloning https://github.com/cocodataset/panopticapi.git to /tmp/pip-install-wo2iehu9/panopticapi_1c57f37c0a5347d2b7cc9e382efa1fc7\n","  Running command git clone -q https://github.com/cocodataset/panopticapi.git /tmp/pip-install-wo2iehu9/panopticapi_1c57f37c0a5347d2b7cc9e382efa1fc7\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (0.29.32)\n","Collecting submitit\n","  Downloading submitit-1.4.5-py3-none-any.whl (73 kB)\n","\u001b[K     |████████████████████████████████| 73 kB 1.8 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.12.0+cu113)\n","Requirement already satisfied: torchvision>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (0.13.0+cu113)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (1.7.3)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (1.1.0)\n","Collecting addict\n","  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n","Collecting yapf\n","  Downloading yapf-0.32.0-py2.py3-none-any.whl (190 kB)\n","\u001b[K     |████████████████████████████████| 190 kB 57.5 MB/s \n","\u001b[?25hCollecting timm\n","  Downloading timm-0.6.7-py3-none-any.whl (509 kB)\n","\u001b[K     |████████████████████████████████| 509 kB 54.6 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools->-r requirements.txt (line 2)) (57.4.0)\n","Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools->-r requirements.txt (line 2)) (3.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from panopticapi->-r requirements.txt (line 6)) (1.21.6)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from panopticapi->-r requirements.txt (line 6)) (7.1.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.5.0->-r requirements.txt (line 4)) (4.1.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.6.0->-r requirements.txt (line 5)) (2.23.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 2)) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 2)) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 2)) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 2)) (1.4.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 2)) (1.15.0)\n","Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from submitit->-r requirements.txt (line 3)) (1.3.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.6.0->-r requirements.txt (line 5)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.6.0->-r requirements.txt (line 5)) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.6.0->-r requirements.txt (line 5)) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.6.0->-r requirements.txt (line 5)) (2.10)\n","Building wheels for collected packages: pycocotools, panopticapi\n","  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycocotools: filename=pycocotools-2.0-cp37-cp37m-linux_x86_64.whl size=265222 sha256=95dce524410a97be4b9b27f8d86db9de4fda997920582eccc5634661832d2c07\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-5gv2fewk/wheels/e2/6b/1d/344ac773c7495ea0b85eb228bc66daec7400a143a92d36b7b1\n","  Building wheel for panopticapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for panopticapi: filename=panopticapi-0.1-py3-none-any.whl size=8306 sha256=e590f699bcfdbaa66fd9ae60b627bf630091b62aea3362608d5ca587bff10f9c\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-5gv2fewk/wheels/ad/89/b8/b66cce9246af3d71d65d72c85ab993fd28e7578e1b0ed197f1\n","Successfully built pycocotools panopticapi\n","Installing collected packages: yapf, timm, submitit, pycocotools, panopticapi, addict\n","  Attempting uninstall: pycocotools\n","    Found existing installation: pycocotools 2.0.4\n","    Uninstalling pycocotools-2.0.4:\n","      Successfully uninstalled pycocotools-2.0.4\n","Successfully installed addict-2.4.0 panopticapi-0.1 pycocotools-2.0 submitit-1.4.5 timm-0.6.7 yapf-0.32.0\n"]}]},{"cell_type":"code","source":["cd models/dino/ops"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"txAnKrvJJwOy","executionInfo":{"status":"ok","timestamp":1660007522285,"user_tz":-540,"elapsed":323,"user":{"displayName":"Haeun Ko","userId":"00138316170718484361"}},"outputId":"0d3d7428-ea3b-4fd5-d1ab-d1f2dc8d8d65"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/DINO/models/dino/ops\n"]}]},{"cell_type":"code","source":["!python setup.py build install"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t-rpKhE5J1t1","executionInfo":{"status":"ok","timestamp":1660007572853,"user_tz":-540,"elapsed":49249,"user":{"displayName":"Haeun Ko","userId":"00138316170718484361"}},"outputId":"e7413945-fb96-4e62-8612-e655f26f2249"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["running build\n","running build_py\n","creating build\n","creating build/lib.linux-x86_64-3.7\n","creating build/lib.linux-x86_64-3.7/modules\n","copying modules/__init__.py -> build/lib.linux-x86_64-3.7/modules\n","copying modules/ms_deform_attn.py -> build/lib.linux-x86_64-3.7/modules\n","creating build/lib.linux-x86_64-3.7/functions\n","copying functions/__init__.py -> build/lib.linux-x86_64-3.7/functions\n","copying functions/ms_deform_attn_func.py -> build/lib.linux-x86_64-3.7/functions\n","running build_ext\n","/usr/local/lib/python3.7/dist-packages/torch/utils/cpp_extension.py:411: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n","  warnings.warn(msg.format('we could not find ninja.'))\n","/usr/local/lib/python3.7/dist-packages/torch/utils/cpp_extension.py:813: UserWarning: The detected CUDA version (11.1) has a minor version mismatch with the version that was used to compile PyTorch (11.3). Most likely this shouldn't be a problem.\n","  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n","building 'MultiScaleDeformableAttention' extension\n","creating build/temp.linux-x86_64-3.7\n","creating build/temp.linux-x86_64-3.7/content\n","creating build/temp.linux-x86_64-3.7/content/DINO\n","creating build/temp.linux-x86_64-3.7/content/DINO/models\n","creating build/temp.linux-x86_64-3.7/content/DINO/models/dino\n","creating build/temp.linux-x86_64-3.7/content/DINO/models/dino/ops\n","creating build/temp.linux-x86_64-3.7/content/DINO/models/dino/ops/src\n","creating build/temp.linux-x86_64-3.7/content/DINO/models/dino/ops/src/cpu\n","creating build/temp.linux-x86_64-3.7/content/DINO/models/dino/ops/src/cuda\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/content/DINO/models/dino/ops/src -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/DINO/models/dino/ops/src/vision.cpp -o build/temp.linux-x86_64-3.7/content/DINO/models/dino/ops/src/vision.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1013\" -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","In file included from \u001b[01m\u001b[K/content/DINO/models/dino/ops/src/vision.cpp:11:0\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/ms_deform_attn.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor ms_deform_attn_forward(const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, int)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/ms_deform_attn.h:29:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","     if (value.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.is_cuda())\n","                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/Tensor.h:3:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/DeviceGuard.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:11\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cpu/ms_deform_attn_cpu.h:12\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/DINO/models/dino/ops/src/ms_deform_attn.h:13\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/DINO/models/dino/ops/src/vision.cpp:11\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:213:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n","                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/content/DINO/models/dino/ops/src/vision.cpp:11:0\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/ms_deform_attn.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kstd::vector<at::Tensor> ms_deform_attn_backward(const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, int)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/ms_deform_attn.h:51:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","     if (value.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.is_cuda())\n","                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/Tensor.h:3:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/DeviceGuard.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:11\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cpu/ms_deform_attn_cpu.h:12\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/DINO/models/dino/ops/src/ms_deform_attn.h:13\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/DINO/models/dino/ops/src/vision.cpp:11\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:213:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n","                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/content/DINO/models/dino/ops/src -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/DINO/models/dino/ops/src/cpu/ms_deform_attn_cpu.cpp -o build/temp.linux-x86_64-3.7/content/DINO/models/dino/ops/src/cpu/ms_deform_attn_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1013\" -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/DINO/models/dino/ops/src -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu -o build/temp.linux-x86_64-3.7/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1013\" -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n","/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/SymInt.h(84): warning: integer conversion resulted in a change of sign\n","\n","/content/DINO/models/dino/ops/src/cuda/ms_deform_im2col_cuda.cuh(261): warning: variable \"q_col\" was declared but never referenced\n","          detected during instantiation of \"void ms_deformable_im2col_cuda(cudaStream_t, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *) [with scalar_t=double]\" \n","/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu(64): here\n","\n","/content/DINO/models/dino/ops/src/cuda/ms_deform_im2col_cuda.cuh(762): warning: variable \"q_col\" was declared but never referenced\n","          detected during instantiation of \"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\" \n","/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu(134): here\n","\n","/content/DINO/models/dino/ops/src/cuda/ms_deform_im2col_cuda.cuh(872): warning: variable \"q_col\" was declared but never referenced\n","          detected during instantiation of \"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\" \n","/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu(134): here\n","\n","/content/DINO/models/dino/ops/src/cuda/ms_deform_im2col_cuda.cuh(331): warning: variable \"q_col\" was declared but never referenced\n","          detected during instantiation of \"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\" \n","/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu(134): here\n","\n","/content/DINO/models/dino/ops/src/cuda/ms_deform_im2col_cuda.cuh(436): warning: variable \"q_col\" was declared but never referenced\n","          detected during instantiation of \"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\" \n","/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu(134): here\n","\n","/content/DINO/models/dino/ops/src/cuda/ms_deform_im2col_cuda.cuh(544): warning: variable \"q_col\" was declared but never referenced\n","          detected during instantiation of \"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\" \n","/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu(134): here\n","\n","/content/DINO/models/dino/ops/src/cuda/ms_deform_im2col_cuda.cuh(649): warning: variable \"q_col\" was declared but never referenced\n","          detected during instantiation of \"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\" \n","/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu(134): here\n","\n","/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/SymInt.h(84): warning: integer conversion resulted in a change of sign\n","\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor ms_deform_attn_cuda_forward(const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, int)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:34:62:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","     AT_ASSERTM(value.type().is_cuda(), \"value must be a CUDA \u001b[01;35m\u001b[Kt\u001b[m\u001b[Kensor\");\n","                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:213:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:35:71:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","     AT_ASSERTM(spatial_shapes.type().is_cuda(), \"spatial_shapes must b\u001b[01;35m\u001b[Ke\u001b[m\u001b[K a CUDA tensor\");\n","                                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:213:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:36:74:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","     AT_ASSERTM(level_start_index.type().is_cuda(), \"level_start_index mus\u001b[01;35m\u001b[Kt\u001b[m\u001b[K be a CUDA tensor\");\n","                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:213:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:37:69:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","     AT_ASSERTM(sampling_loc.type().is_cuda(), \"sampling_loc must be \u001b[01;35m\u001b[Ka\u001b[m\u001b[K CUDA tensor\");\n","                                                                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:213:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:38:68:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","     AT_ASSERTM(attn_weight.type().is_cuda(), \"attn_weight must be a\u001b[01;35m\u001b[K \u001b[m\u001b[KCUDA tensor\");\n","                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:213:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:\u001b[m\u001b[K In lambda function:\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:64:43:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","         AT_DISPATCH_FLOATING_TYPES(value.t\u001b[01;35m\u001b[Ky\u001b[m\u001b[Kpe(), \"ms_deform_attn_forward_cuda\", ([&] {\n","                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:213:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:64:98:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n","                                                                                                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:178:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n"," \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:\u001b[m\u001b[K In lambda function:\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:64:814:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:235:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:64:900:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:235:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:64:943:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:235:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:64:976:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:235:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:64:1059:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:235:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:64:1217:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:235:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:\u001b[m\u001b[K In lambda function:\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:64:1922:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:235:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:64:2008:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:235:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:64:2051:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:235:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:64:2083:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:235:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:64:2165:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:235:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:64:2322:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:235:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kstd::vector<at::Tensor> ms_deform_attn_cuda_backward(const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, int)\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:100:62:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","     AT_ASSERTM(value.type().is_cuda(), \"value must be a CUDA \u001b[01;35m\u001b[Kt\u001b[m\u001b[Kensor\");\n","                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:213:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:101:71:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","     AT_ASSERTM(spatial_shapes.type().is_cuda(), \"spatial_shapes must b\u001b[01;35m\u001b[Ke\u001b[m\u001b[K a CUDA tensor\");\n","                                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:213:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:102:74:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","     AT_ASSERTM(level_start_index.type().is_cuda(), \"level_start_index mus\u001b[01;35m\u001b[Kt\u001b[m\u001b[K be a CUDA tensor\");\n","                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:213:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:103:69:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","     AT_ASSERTM(sampling_loc.type().is_cuda(), \"sampling_loc must be \u001b[01;35m\u001b[Ka\u001b[m\u001b[K CUDA tensor\");\n","                                                                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:213:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:104:68:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","     AT_ASSERTM(attn_weight.type().is_cuda(), \"attn_weight must be a\u001b[01;35m\u001b[K \u001b[m\u001b[KCUDA tensor\");\n","                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:213:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:105:68:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","     AT_ASSERTM(grad_output.type().is_cuda(), \"grad_output must be a\u001b[01;35m\u001b[K \u001b[m\u001b[KCUDA tensor\");\n","                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:213:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:\u001b[m\u001b[K In lambda function:\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:43:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","         AT_DISPATCH_FLOATING_TYPES(value.t\u001b[01;35m\u001b[Ky\u001b[m\u001b[Kpe(), \"ms_deform_attn_backward_cuda\", ([&] {\n","                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:213:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:98:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n","                                                                                                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:178:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n"," \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:\u001b[m\u001b[K In lambda function:\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:824:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:235:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:850:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:235:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:936:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:235:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:979:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:235:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:1012:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:235:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:1095:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:235:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:1256:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:235:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:1340:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:235:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:1428:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:235:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:\u001b[m\u001b[K In lambda function:\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:2195:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:235:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:2220:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:235:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:2306:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:235:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:2349:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:235:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:2381:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:235:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:2463:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:235:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:2623:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:235:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:2706:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:235:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:2793:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:235:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/content/DINO/models/dino/ops/src/vision.o build/temp.linux-x86_64-3.7/content/DINO/models/dino/ops/src/cpu/ms_deform_attn_cpu.o build/temp.linux-x86_64-3.7/content/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.7/MultiScaleDeformableAttention.cpython-37m-x86_64-linux-gnu.so\n","running install\n","running bdist_egg\n","running egg_info\n","creating MultiScaleDeformableAttention.egg-info\n","writing MultiScaleDeformableAttention.egg-info/PKG-INFO\n","writing dependency_links to MultiScaleDeformableAttention.egg-info/dependency_links.txt\n","writing top-level names to MultiScaleDeformableAttention.egg-info/top_level.txt\n","writing manifest file 'MultiScaleDeformableAttention.egg-info/SOURCES.txt'\n","writing manifest file 'MultiScaleDeformableAttention.egg-info/SOURCES.txt'\n","installing library code to build/bdist.linux-x86_64/egg\n","running install_lib\n","creating build/bdist.linux-x86_64\n","creating build/bdist.linux-x86_64/egg\n","copying build/lib.linux-x86_64-3.7/MultiScaleDeformableAttention.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n","creating build/bdist.linux-x86_64/egg/modules\n","copying build/lib.linux-x86_64-3.7/modules/__init__.py -> build/bdist.linux-x86_64/egg/modules\n","copying build/lib.linux-x86_64-3.7/modules/ms_deform_attn.py -> build/bdist.linux-x86_64/egg/modules\n","creating build/bdist.linux-x86_64/egg/functions\n","copying build/lib.linux-x86_64-3.7/functions/__init__.py -> build/bdist.linux-x86_64/egg/functions\n","copying build/lib.linux-x86_64-3.7/functions/ms_deform_attn_func.py -> build/bdist.linux-x86_64/egg/functions\n","byte-compiling build/bdist.linux-x86_64/egg/modules/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/modules/ms_deform_attn.py to ms_deform_attn.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/functions/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/functions/ms_deform_attn_func.py to ms_deform_attn_func.cpython-37.pyc\n","creating stub loader for MultiScaleDeformableAttention.cpython-37m-x86_64-linux-gnu.so\n","byte-compiling build/bdist.linux-x86_64/egg/MultiScaleDeformableAttention.py to MultiScaleDeformableAttention.cpython-37.pyc\n","creating build/bdist.linux-x86_64/egg/EGG-INFO\n","copying MultiScaleDeformableAttention.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying MultiScaleDeformableAttention.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying MultiScaleDeformableAttention.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying MultiScaleDeformableAttention.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n","zip_safe flag not set; analyzing archive contents...\n","__pycache__.MultiScaleDeformableAttention.cpython-37: module references __file__\n","creating dist\n","creating 'dist/MultiScaleDeformableAttention-1.0-py3.7-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n","removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n","Processing MultiScaleDeformableAttention-1.0-py3.7-linux-x86_64.egg\n","creating /usr/local/lib/python3.7/dist-packages/MultiScaleDeformableAttention-1.0-py3.7-linux-x86_64.egg\n","Extracting MultiScaleDeformableAttention-1.0-py3.7-linux-x86_64.egg to /usr/local/lib/python3.7/dist-packages\n","Adding MultiScaleDeformableAttention 1.0 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.7/dist-packages/MultiScaleDeformableAttention-1.0-py3.7-linux-x86_64.egg\n","Processing dependencies for MultiScaleDeformableAttention==1.0\n","Finished processing dependencies for MultiScaleDeformableAttention==1.0\n"]}]},{"cell_type":"code","source":["!python test.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p4MXlED_KGJJ","executionInfo":{"status":"ok","timestamp":1660007643394,"user_tz":-540,"elapsed":65708,"user":{"displayName":"Haeun Ko","userId":"00138316170718484361"}},"outputId":"adfae905-fa91-4658-cfe4-3a830a091903"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["* True check_forward_equal_with_pytorch_double: max_abs_err 8.67e-19 max_rel_err 2.35e-16\n","* True check_forward_equal_with_pytorch_float: max_abs_err 4.66e-10 max_rel_err 1.13e-07\n","* True check_gradient_numerical(D=30)\n","* True check_gradient_numerical(D=32)\n","* True check_gradient_numerical(D=64)\n","* True check_gradient_numerical(D=71)\n","* True check_gradient_numerical(D=1025)\n","Traceback (most recent call last):\n","  File \"test.py\", line 86, in <module>\n","    check_gradient_numerical(channels, True, True, True)\n","  File \"test.py\", line 76, in check_gradient_numerical\n","    gradok = gradcheck(func, (value.double(), shapes, level_start_index, sampling_locations.double(), attention_weights.double(), im2col_step))\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/gradcheck.py\", line 1414, in gradcheck\n","    return _gradcheck_helper(**args)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/gradcheck.py\", line 1431, in _gradcheck_helper\n","    check_undefined_grad=check_undefined_grad)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/gradcheck.py\", line 1076, in _gradcheck_real_imag\n","    rtol, atol, check_grad_dtypes, nondet_tol)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/gradcheck.py\", line 1111, in _slow_gradcheck\n","    numerical = _transpose(_get_numerical_jacobian(func, tupled_inputs, outputs, eps=eps, is_forward_ad=use_forward_ad))\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/gradcheck.py\", line 152, in _get_numerical_jacobian\n","    input=inp, is_forward_ad=is_forward_ad)]\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/gradcheck.py\", line 295, in get_numerical_jacobian_wrt_specific_input\n","    return _combine_jacobian_cols(jacobian_cols, outputs, input, input.numel())\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/gradcheck.py\", line 235, in _combine_jacobian_cols\n","    jacobians = _allocate_jacobians_with_outputs(outputs, numel, dtype=input.dtype if input.dtype.is_complex else None)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/gradcheck.py\", line 50, in _allocate_jacobians_with_outputs\n","    out.append(t.new_zeros((numel_input, t.numel()), **options))\n","RuntimeError: CUDA out of memory. Tried to allocate 7.50 GiB (GPU 0; 14.76 GiB total capacity; 7.50 GiB already allocated; 6.66 GiB free; 7.50 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"]}]},{"cell_type":"code","source":["cd /content/DINO"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V7YzGZryJ5zB","executionInfo":{"status":"ok","timestamp":1660007667442,"user_tz":-540,"elapsed":301,"user":{"displayName":"Haeun Ko","userId":"00138316170718484361"}},"outputId":"4d8d5c2a-2b7e-46d3-a8b3-85db1184bf74"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/DINO\n"]}]},{"cell_type":"markdown","source":["###Inference"],"metadata":{"id":"WRzbO-tO311g"}},{"cell_type":"markdown","source":["https://github.com/IDEACVR/DINO/blob/main/inference_and_visualization.ipynb"],"metadata":{"id":"zb-Ofg8q30HG"}},{"cell_type":"code","source":["import os, sys\n","import torch, json\n","import numpy as np\n","\n","from main import build_model_main\n","from util.slconfig import SLConfig\n","from datasets import build_dataset\n","from util.visualizer import COCOVisualizer\n","from util import box_ops"],"metadata":{"id":"3C06nmf330yl","colab":{"base_uri":"https://localhost:8080/","height":532},"executionInfo":{"status":"error","timestamp":1660007670194,"user_tz":-540,"elapsed":1549,"user":{"displayName":"Haeun Ko","userId":"00138316170718484361"}},"outputId":"f302a817-ef7e-4741-8c3b-9d044005edc2"},"execution_count":8,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-0fffbd493ea3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_model_main\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSLConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/DINO/main.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_coco_api_from_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDictAction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSLConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelEma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBestMetricHolder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/DINO/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# ------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdino\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_dino\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/DINO/models/dino/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# ------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdino\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_dino\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/DINO/models/dino/dino.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m from .segmentation import (DETRsegm, PostProcessPanoptic, PostProcessSegm,\n\u001b[1;32m     32\u001b[0m                            dice_loss)\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdeformable_transformer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_deformable_transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msigmoid_focal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/DINO/models/dino/deformable_transformer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen_encoder_output_proposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_get_activation_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_sineembed_for_position\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMSDeformAttn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDeformableTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/DINO/models/dino/ops/modules/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# ------------------------------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mms_deform_attn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMSDeformAttn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/DINO/models/dino/ops/modules/ms_deform_attn.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxavier_uniform_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstant_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMSDeformAttnFunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/DINO/models/dino/ops/functions/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# ------------------------------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mms_deform_attn_func\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMSDeformAttnFunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/DINO/models/dino/ops/functions/ms_deform_attn_func.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0monce_differentiable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mMultiScaleDeformableAttention\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mMSDA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'MultiScaleDeformableAttention'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["model_config_path = \"config/DINO/DINO_4scale.py\" # change the path of the model config file\n","model_checkpoint_path = \"ckpts/checkpoint0023_4scale.pth\" # change the path of the model checkpoint\n","\n","# See our Model Zoo section in README.md for more details about our pretrained models.\n","args = SLConfig.fromfile(model_config_path) \n","args.device = 'cuda' \n","model, criterion, postprocessors = build_model_main(args)\n","checkpoint = torch.load(model_checkpoint_path, map_location='cpu')\n","model.load_state_dict(checkpoint['model'])\n","model.eval()\n","\n","# load coco names\n","with open('util/coco_id2name.json') as f:\n","    id2name = json.load(f)\n","    id2name = {int(k):v for k,v in id2name.items()}"],"metadata":{"id":"v8OksVOlFZh2"},"execution_count":null,"outputs":[]}]}