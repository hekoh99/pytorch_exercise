{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Define autograd Function.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN/C4Rkmnrfu1kPNcLl9DXK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["##autograd function 정의\n","torch.autograd.Function을 상속받아 사용자 정의 autograd Function을 구현하고, 텐서 연산을 하는 순전파 단계와 역전파 단계를 구현"],"metadata":{"id":"xuocxjYHsg8J"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"95RXdh-ypszC","executionInfo":{"status":"ok","timestamp":1653540617857,"user_tz":-540,"elapsed":3063,"user":{"displayName":"Haeun Ko","userId":"00138316170718484361"}}},"outputs":[],"source":["import torch\n","import math"]},{"cell_type":"code","source":["class LegendrePolynomial3(torch.autograd.Function):\n","\n","    @staticmethod\n","    def forward(ctx, input):\n","        \"\"\"\n","        순전파 단계에서는 입력을 갖는 텐서를 받아 출력을 갖는 텐서를 반환\n","        ctx는 컨텍스트 객체(context object)로 역전파 연산을 위한 정보 저장에 사용함.\n","        ctx.save_for_backward 메소드를 사용하여 역전파 단계에서 사용할 객체를 저장할 수(캐싱해 둘 수) 있음\n","        \"\"\"\n","        ctx.save_for_backward(input)\n","        return 0.5 * (5 * input ** 3 - 3 * input)\n","\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        \"\"\"\n","        역전파 단계에서는 출력에 대한 손실(loss)의 변화도(gradient)를 갖는 텐서를 받고,\n","        입력에 대한 손실의 변화도를 계산해야 함.\n","        \"\"\"\n","        input, = ctx.saved_tensors\n","        return grad_output * 1.5 * (5 * input ** 2 - 1)"],"metadata":{"id":"DFSh-qCgs-Go","executionInfo":{"status":"ok","timestamp":1653540700024,"user_tz":-540,"elapsed":281,"user":{"displayName":"Haeun Ko","userId":"00138316170718484361"}}},"execution_count":2,"outputs":[]}]}